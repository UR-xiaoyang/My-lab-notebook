## 4. 结果与分析

*   **原始数据分析 (`train.csv`)**:
    *   `Age` 和 `Cabin` 列存在大量缺失值，`Embarked` 有少量缺失值。
    *   `Fare` 票价特征呈现高度右偏分布。
    *   可视化分析显示，性别（女性生存率更高）、船票等级（高等舱生存率更高）与生存率有明显关联。
*   **数据清洗影响**:
    *   直接删除所有含缺失值的行导致数据集从891行锐减至183行。这是一种非常激进的清洗策略，极大地减少了可用于模型训练的数据量，并可能不成比例地移除了某些特征或乘客群体，从而引入了偏差。
*   **清理后数据分析 (`train_kill_nan.csv`)**:
    *   数据集无缺失值。
    *   由于数据量大幅减少，某些特征的分布可能与原始数据集有所不同，需要通过 `preview_cleaned_data.py` 的可视化进行对比确认。
*   **模型训练与评估 (基于 `train_kill_nan.csv`)**:

    *   **4.a. 初始逻辑回归模型 (无额外特征工程)**
        *   **特征使用**: `Pclass`, `Sex`, `Age`, `SibSp`, `Parch`, `Fare`, `Embarked`。分类特征进行独热编码，数值特征进行标准化。
        *   **准确率**: 在测试集上达到了约 **70.09%** (此为特征工程前的记录)。
        *   **模型系数 (基于此模型配置)**:
            *   `Sex_female` 具有较大的正系数，表明女性是强生存预测因子。
            *   `Pclass_1` 具有正系数，`Pclass_3` 具有负系数，表明船舱等级的影响。
            *   `Age` 具有负系数，表明年龄较大生存几率略低（在该数据子集和模型中）。
        *   **讨论**: 此为基线模型表现，在此基础上尝试了特征工程。

    *   **4.b. 逻辑回归模型 (应用特征工程: Title, FamilySize, Deck)**
        *   **特征使用**: 数值特征: `Age`, `Fare`, `FamilySize` (进行了标准化); 分类特征: `Pclass`, `Sex`, `Embarked`, `Title`, `Deck` (进行了独热编码)。原始的 `SibSp` 和 `Parch` 被 `FamilySize` 替代。
        *   **准确率**: 在使用**完整 \`train.csv\` 数据集**并采用**更精细的缺失值处理策略**（Age使用中位数填充，Embarked使用众数填充，Cabin缺失生成的Deck填充为'U'）后，模型在测试集上的准确率达到了 **77.75%** (即 0.77751)。
        *   **分析与讨论**:
            *   此次结果（77.75%）是基于**使用完整 \`train.csv\` 数据集**，并对 \`Age\`（中位数填充）、\`Embarked\`（众数填充）进行了缺失值插补，同时 \`Deck\` 特征中的缺失值（源于 \`Cabin\`）被处理为 'U'。此前的 74.88% 准确率（本节先前记录）是在仅有183条记录的 \`train_kill_nan.csv\` 数据集上取得的（该数据集直接删除了所有含缺失值的行）。
            *   对比先前在小数据集 (\`train_kill_nan.csv\`) 上的结果：
                *   初始逻辑回归模型（无额外特征工程，见4.a节）准确率约为 70.09%。
                *   同样应用本节所述的特征工程（Title, FamilySize, Deck）后，在小数据集上准确率提升至 74.88%。
            *   本次通过采用**更优的数据保留和缺失值处理策略**，在同样的特征工程和逻辑回归模型基础上，准确率从74.88%进一步提升至 77.75%。这有力地证明了数据量和合理的缺失值处理对模型性能的显著正面影响。
            *   尽管准确率得到提升，模型仍有改进空间。未来可以尝试实验报告中提及的其他方法，如更复杂的模型、进一步的特征工程或超参数调优。
        *   **分类报告**: (此处的具体数值可能需要根据实际运行的详细报告更新，以下为通用观察保留)
            *   需要对比详细分类报告来查看各类别（生存/未生存）的精确率、召回率和F1分数的变化。
        *   **模型系数**: (由于特征变化，具体系数解读会不同)
            *   新的特征如 `Title`, `FamilySize`, `Deck` 会有其对应的系数，反映它们对预测生存的贡献。这些系数的解读将帮助理解模型如何使用这些新特征。
        *   **可视化评估**:
            *   混淆矩阵和ROC曲线（及AUC值）可以进一步对比两个模型在区分能力上的差异。初始模型的AUC约为0.83。

    *   **4.c. 随机森林模型 (应用相同特征工程与交叉验证)**
        *   **模型与数据**: 在与上一节 (4.b) 相同的特征工程、数据预处理（完整 \`train.csv\` 数据集，Age使用中位数填充，Embarked使用众数填充，Deck的\'U\'处理）基础上，将模型替换为随机森林分类器 (`RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)`)。
        *   **交叉验证**: 在训练数据上应用了5折交叉验证评估模型。交叉验证的平均准确率约为 (请根据脚本输出填写，例如: 80.12% +/- 2.50%)。
        *   **测试集准确率**: 模型在测试集上的最终准确率为 **75.84%** (即 0.75837)。
        *   **分析与讨论**:
            *   与前述逻辑回归模型所达到的77.75%准确率相比，随机森林分类器（使用默认参数）在此次实验中的表现略有下降。
            *   这可能是因为随机森林的默认超参数并非此数据集的最优配置，或者其对此特定特征集的学习方式与逻辑回归有所不同。
            *   尽管随机森林是一种通常表现优异的模型，但这个结果提示了进行细致的超参数调优对于发掘其全部潜力至关重要。未来可以针对随机森林进行网格搜索或随机搜索等超参数优化方法。
            *   同时，这也说明并非所有复杂模型都能在默认情况下超越经过细致数据处理和特征工程的简单模型。

    *   **4.d. 逻辑回归模型 (进一步特征工程: Age和Fare分箱)**
        *   **背景**: 此实验在4.b节的逻辑回归模型基础上，进一步对 `Age` 和 `Fare` 特征进行了分箱处理，旨在探索这种离散化方法对模型性能的提升效果。
        *   **数据与预处理**: 使用**完整 \`train.csv\` 数据集**。缺失值处理策略与4.b节一致：`Age` 和 `Fare` 在分箱前使用各自的中位数填充，`Embarked` 使用众数填充，`Cabin` 缺失导致的 `Deck` 特征填充为 \'U'。
        *   **特征工程**: 
            *   保留了 `Title`, `FamilySize`, `Deck` 特征。
            *   新增 `AgeBin`: 将填充后的 `Age` 特征分箱为 \'Child\', \'Teenager\', \'Adult\', \'MiddleAged\', \'Senior\'。
            *   新增 `FareBin`: 将填充后的 `Fare` 特征基于四分位数分箱为 \'LowFare\', \'MedFare\', \'HighFare\', \'VeryHighFare\' (包含对分箱边界值非唯一的处理逻辑)。
            *   原始的 `Age` 和 `Fare` 数值特征被其对应的分箱后类别特征替代。
        *   **模型**: 逻辑回归 (`LogisticRegression(solver='liblinear', random_state=42, C=0.1, penalty='l1', max_iter=1000)`)。
        *   **准确率**: 模型在测试集上的准确率达到了 **78.23%** (即 0.78229)。
        *   **分析与讨论**:
            *   与4.b节中使用相同数据处理方式和逻辑回归模型、但未对 `Age` 和 `Fare` 进行分箱（准确率77.75%）的结果相比，**本次通过引入 `AgeBin` 和 `FareBin` 特征，准确率提升至78.23%**。
            *   这表明对于泰坦尼克号数据集，将 `Age` 和 `Fare` 这两个连续型数值特征转化为离散的、有序的类别特征（分箱），能够帮助逻辑回归模型更好地捕捉它们与生存率之间的非线性关系或特定区间的模式，从而提高了预测的准确性。
            *   此结果进一步强调了特征工程在提升模型性能方面的关键作用，即使是相对简单的模型，通过精心设计的特征也能取得不错的表现。
            *   分类报告和模型系数（特别是 `AgeBin` 和 `FareBin` 各个类别的系数）可以提供更深入的洞察，了解不同年龄段和票价区间的乘客对生存预测的具体贡献。

    *   **4.e. 随机森林模型 (应用特征工程与GridSearchCV超参数调优)**
        *   **背景**: 此实验在4.d节的特征工程基础上（即使用 `Title`, `FamilySize`, `Deck`, `AgeBin`, `FareBin` 特征），将模型替换为随机森林分类器，并使用 `GridSearchCV` 进行了超参数调优，以探索其性能。
        *   **数据与预处理**: 与4.d节完全一致，使用完整 `train.csv` 数据集及相同的缺失值处理和特征工程策略。
        *   **模型**: 随机森林分类器 (`RandomForestClassifier`)，通过 `GridSearchCV` 搜索包括 `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`, `class_weight` 在内的参数。
        *   **GridSearchCV结果**: 
            *   最佳交叉验证准确率 (`best_score_`): (请根据脚本输出填写，例如: 0.8012)
            *   最佳参数 (`best_params_`): (请根据脚本输出填写，例如: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 2, ...})
        *   **测试集准确率**: 模型在测试集上的准确率达到了 **77.75%** (即 0.77751)。
        *   **分析与讨论**:
            *   与4.d节中使用相同特征集但采用逻辑回归模型（准确率78.23%）的结果相比，本次经过 `GridSearchCV` 调优的随机森林模型准确率为77.75%，略有下降。
            *   这表明在此特定数据集和特征工程组合下，经过调优的随机森林模型并未超越表现最佳的逻辑回归模型。
            *   可能的原因包括：随机森林的超参数搜索空间仍有优化的可能；或者对于当前特征集，逻辑回归的决策边界可能更适合此分类任务。
            *   尽管随机森林是一种强大的模型，但这个结果再次说明了没有"万能"的模型，模型选择和调优需要结合具体数据和问题进行。
            *   未来可以尝试更广泛的超参数搜索范围，或者尝试其他的集成学习模型，如梯度提升机。

    *   **4.f. 逻辑回归模型 (进一步特征工程: 新增交互特征)**
        *   **背景**: 此实验在4.d节的逻辑回归模型和特征工程（`Title`, `FamilySize`, `Deck`, `AgeBin`, `FareBin`）基础上，进一步向特征集中添加了交互特征，旨在评估这些组合特征对模型性能的提升效果。
        *   **数据与预处理**: 与4.d节完全一致，使用完整 `train.csv` 数据集及相同的缺失值处理（`Age` 和 `Fare` 在分箱前使用各自的中位数填充，`Embarked` 使用众数填充，`Cabin` 缺失导致的 `Deck` 特征填充为 'U'）。
        *   **新增特征工程**:
            *   保留了 `Title`, `FamilySize`, `Deck`, `AgeBin`, `FareBin` 特征。
            *   新增交互特征: `AgeBin_Pclass` (AgeBin 和 Pclass 的组合), `Title_Pclass` (Title 和 Pclass 的组合), `Sex_Pclass` (Sex 和 Pclass 的组合)。这些交互特征被视为分类特征进行独热编码。
        *   **模型**: 逻辑回归 (`LogisticRegression(solver='liblinear', random_state=42, C=0.1, penalty='l1', max_iter=1000)`)，与4.d节中表现最佳的逻辑回归模型配置相同。
        *   **准确率**: 模型在测试集上的准确率达到了 **78.47%** (即 0.78468)。
        *   **分析与讨论**:
            *   与4.d节中使用相同逻辑回归模型、但未包含这些交互特征（准确率78.23%）的结果相比，**本次通过引入 `AgeBin_Pclass`, `Title_Pclass`, `Sex_Pclass` 交互特征，准确率从78.23%提升至78.47%**。
            *   这一小幅提升表明，对于泰坦尼克号数据集，明确地将某些特征之间的交互关系作为新特征提供给逻辑回归模型，可以帮助模型捕捉到更细致的模式，从而略微改善预测的准确性。
            *   尽管提升幅度不大，但它验证了特征交互是提升模型性能的一个有效方向。未来可以考虑探索更多潜在有用的特征交互。
            *   下一步可以评估这些新增的交互特征对于其他模型（如随机森林或梯度提升机）性能的影响。 

    *   **4.g. 梯度提升机模型 (应用特征工程与超参数调优)**
        *   **背景**: 此实验在4.f节的特征工程基础之上（即使用 `Title`, `FamilySize`, `Deck`, `AgeBin`, `FareBin` 以及交互特征 `AgeBin_Pclass`, `Title_Pclass`, `Sex_Pclass`），将模型替换为梯度提升分类器 (例如 `XGBoostClassifier` 或 `LGBMClassifier`)，并进行超参数调优，以探索其性能潜力。
        *   **数据与预处理**: 与4.f节完全一致，使用完整 `train.csv` 数据集及相同的缺失值处理和特征工程策略。
        *   **模型**: 梯度提升分类器 (例如 `XGBoostClassifier` 或 `LGBMClassifier`)。建议使用 `GridSearchCV` 或 `RandomizedSearchCV` 优化关键超参数，例如（但不限于）：
            *   `n_estimators` (树的数量)
            *   `learning_rate` (学习率)
            *   `max_depth` (树的最大深度)
            *   `subsample` (训练每棵树时样本的采样比例)
            *   `colsample_bytree` (训练每棵树时特征的采样比例)
            *   （对于LightGBM还可考虑 `num_leaves`, `min_child_samples` 等）
        *   **GridSearchCV/RandomizedSearchCV 结果**: 
            *   最佳交叉验证准确率 (`best_score_`): (请根据脚本输出填写，例如: 0.8134)
            *   最佳参数 (`best_params_`): (请根据脚本输出填写，例如: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 3, 'classifier__n_estimators': 100, 'classifier__subsample': 0.8, 'classifier__colsample_bytree': 0.8})
        *   **测试集准确率**: **0.77990**
        *   **分析与讨论**:
            *   将此模型的准确率 (0.77990) 与先前最佳的逻辑回归模型（4.f节，78.47%）进行比较。可以看到，经过GridSearchCV调优的XGBoost模型在此次实验中的表现略低于逻辑回归模型。
            *   尽管XGBoost通常被认为是强大的模型，但这个结果表明，对于当前精心构建的特征集，逻辑回归模型可能已经达到了一个较好的性能瓶颈，或者XGBoost的超参数搜索空间/调优策略仍有进一步优化的潜力。
            *   可以回顾XGBoost输出的特征重要性，了解模型主要依赖哪些特征。如果与逻辑回归的系数反映的特征重要性有较大差异，可能揭示了模型学习模式的不同。
            *   未来可以尝试更广泛或更精细的XGBoost超参数搜索，或者考虑结合不同模型的预测（模型集成/堆叠）来寻求进一步的提升。 

    *   **4.h. 逻辑回归模型 (基于4.f特征进行GridSearchCV超参数调优)**
        *   **背景**: 此实验在4.f节的逻辑回归模型和特征工程基础之上（即使用 `Title`, `FamilySize`, `Deck`, `AgeBin`, `FareBin` 以及交互特征 `AgeBin_Pclass`, `Title_Pclass`, `Sex_Pclass`），对逻辑回归模型本身运用 `GridSearchCV` 进行了超参数调优。
        *   **数据与预处理**: 与4.f节完全一致，使用完整 `train.csv` 数据集及相同的缺失值处理和特征工程策略。
        *   **模型**: 逻辑回归 (`LogisticRegression`)，通过 `GridSearchCV` 优化 `classifier__C` (例如 `[0.001, 0.01, 0.1, 1, 10, 100]`) 和 `classifier__penalty` (例如 `['l1', 'l2']`) 等参数，求解器使用 `liblinear`。
        *   **GridSearchCV结果**: 
            *   最佳交叉验证准确率 (`best_score_`): (请根据脚本输出填写，例如: 0.7887)
            *   最佳参数 (`best_params_`): (请根据脚本输出填写，例如: {'classifier__C': 0.1, 'classifier__penalty': 'l1'})
        *   **测试集准确率**: 本次实验中，经过 `GridSearchCV` 超参数调优的逻辑回归模型在测试集上的准确率达到了 **0.77990**。
        *   **分析与讨论**:
            *   与4.f节中使用相同特征集但手动设置参数（`C=0.1, penalty='l1', solver='liblinear'`）的逻辑回归模型（准确率0.78468）相比，本次通过 `GridSearchCV` 调优后的模型准确率为0.77990，表现略有下降。
            *   这可能表明先前在4.f节中手动选择的参数组合 (`C=0.1, penalty='l1'`) 对于该特定的特征集和数据划分已经非常接近或就是最优状态，而 `GridSearchCV` 在其定义的搜索空间内找到的最优参数在测试集上的泛化能力略逊于原设定。
            *   另一种可能性是，交叉验证过程中的数据划分方式（即使 `random_state` 固定，`GridSearchCV` 内部的划分也可能引入微小变动）或测试集本身的特性，导致了这种微小的性能差异。
            *   此结果提示，虽然超参数调优是提升模型性能的常用手段，但并非总能超越一个已经精心调整过的基线模型，特别是在特征工程已经比较完善的情况下。未来如果继续优化逻辑回归，可能需要更精细的参数搜索范围或者结合模型的学习曲线来判断是否存在过拟合或欠拟合。 

    *   **4.i. 支持向量机 (SVM) 模型 (应用特征工程与超参数调优)**
        *   **背景**: 此实验在4.f节的特征工程基础之上（即使用 `Title`, `FamilySize`, `Deck`, `AgeBin`, `FareBin` 以及交互特征 `AgeBin_Pclass`, `Title_Pclass`, `Sex_Pclass`），将模型替换为支持向量机分类器 (`SVC`)，并使用 `GridSearchCV` 进行了超参数调优。
        *   **数据与预处理**: 与4.f节完全一致，使用完整 `train.csv` 数据集及相同的缺失值处理和特征工程策略。所有特征在输入SVM前都经过了标准化处理（通过预处理管道实现）。
        *   **模型**: 支持向量机分类器 (`SVC`)，通过 `GridSearchCV` 搜索包括 `C` (正则化参数), `kernel` (核函数，如 'linear', 'rbf'), `gamma` (对于 'rbf' 核) 在内的参数。
        *   **GridSearchCV结果**:
            *   最佳交叉验证准确率 (`best_score_`): (请根据脚本 `train_model.py` 输出填写)
            *   最佳参数 (`best_params_`): (请根据脚本 `train_model.py` 输出填写)
        *   **测试集准确率**: 0.77272
        *   **分析与讨论**:
            *   (请在运行脚本后，根据实际结果填写此部分。比较SVM的性能与先前模型，如逻辑回归和XGBoost的性能。讨论最佳参数、核函数选择的影响，以及SVM在此问题上的表现。)
            *   (如果线性核表现最佳，可以分析其系数，类似于逻辑回归。)
            *   (如果RBF核表现最佳，可以讨论 `C` 和 `gamma` 的影响。)
            *   (分析混淆矩阵和ROC AUC，评估其分类性能和鲁棒性。) 

    *   **4.j. 支持向量机 (SVM) 模型 (应用特征工程与固定参数)**
        *   **背景**: 此实验在4.f节的特征工程基础之上（即使用 `Title`, `FamilySize`, `Deck`, `AgeBin`, `FareBin` 以及交互特征 `AgeBin_Pclass`, `Title_Pclass`, `Sex_Pclass`），将模型替换为支持向量机分类器 (`SVC`)。与4.i节计划的`GridSearchCV`调优不同，本实验直接使用了固定的超参数，旨在评估一个基础配置的SVM模型在当前特征集上的表现，并与可能的调优结果进行对比。
        *   **数据与预处理**: 与4.f节完全一致，使用完整 `train.csv` 数据集及相同的缺失值处理和特征工程策略。所有特征在输入SVM前都经过了标准化处理（通过预处理管道实现）。
        *   **模型**: 支持向量机分类器 (`SVC`)，参数设置为 `C=1.0`, `kernel='rbf'`, `gamma='scale'`, `probability=True`, `random_state=42`。
        *   **测试集准确率**: **0.77272**
        *   **分析与讨论**:
            *   本次使用固定参数（`C=1.0`, `kernel='rbf'`, `gamma='scale'`）的SVM模型在测试集上获得了0.77272的准确率。
            *   这个分数与4.i节中记录的（可能是预期的或先前运行的）使用`GridSearchCV`调优的SVM模型的准确率相同。这可能表明：
                *   对于此数据集和特征集，`GridSearchCV`可能未找到显著优于这些常用默认/基础参数的参数组合。
                *   或者，所选的固定参数恰好接近或就是该搜索空间内的最优（或接近最优）参数。
                *   SVM模型对于这些超参数的调整在该特定数据集上的敏感度可能不高。
            *   与项目中其他模型（如4.f节的逻辑回归模型，准确率0.78468）相比，此SVM模型的表现略低。
            *   未来若要进一步提升SVM性能，可以考虑尝试更广泛的参数搜索（如果怀疑当前固定参数或4.i的搜索范围不足），或者探索不同的核函数，亦或检查特征缩放对SVM性能的极致影响。然而，鉴于当前结果，可能优先投入资源优化其他表现更好的模型或进行更深入的特征工程。
            *   （可根据实际运行 `train_model.py` 后输出的混淆矩阵、ROC AUC等信息进一步补充详细的分类性能分析。） 

    *   **4.k. 支持向量机 (SVM) 模型 (基于4.j固定参数)**
        *   **背景**: 此条目记录将4.j节中训练的支持向量机（SVC）模型生成的预测结果 (`submission_svm_4j.csv`) 提交到Kaggle平台进行评估的结果。
        *   **模型与数据**: 
            *   模型配置与4.j节完全一致：`SVC(C=1.0, kernel='rbf', gamma='scale', probability=True, random_state=42)`。
            *   特征工程策略与4.f节一致（`Title`, `FamilySize`, `Deck`, `AgeBin`, `FareBin` 及交互特征 `AgeBin_Pclass`, `Title_Pclass`, `Sex_Pclass`）。
            *   数据预处理（缺失值填充、标准化等）与4.j节一致。
        *   **Kaggle 公开排行榜得分**: **0.77272**
        *   **分析与讨论**:
            *   本次在Kaggle公开排行榜上获得的准确率 (0.77272) 与4.j节中记录的该模型在本地验证集（或特定测试分割）上的准确率完全相同。这表明本地的验证策略和数据集划分能较好地反映模型在Kaggle测试集上的泛化能力。
            *   与项目中其他模型的表现相比：
                *   4.f节的逻辑回归模型（添加交互特征，手动调参）在本地验证集上的准确率为0.78468。
                *   4.g节的XGBoost模型（GridSearchCV调优）在Kaggle（或本地测试集）上的准确率为0.77990。
                *   4.h节的逻辑回归模型（GridSearchCV调优）在本地测试集上的准确率为0.77990。
            *   结果表明，当前采用固定参数的SVM模型 (0.77272) 在Kaggle上的表现略低于经过特征工程优化的逻辑回归模型 (如4.f，本地验证0.78468) 和调优后的XGBoost/逻辑回归模型 (如4.g/4.h，约0.77990)。
            *   这进一步印证了4.j节的初步结论，即虽然SVM是一个强大的分类器，但在此特定数据集和特征组合下，其默认/基础参数配置的表现并未超越其他经过细致调整的模型。未来若要提升SVM性能，可能需要更细致的超参数调优（如4.i节原计划）或进一步的特征探索。 

    *   **4.l. 神经网络模型 (应用特征工程)**
        *   **背景**: 此实验在4.f节的特征工程基础之上（即使用 `Title`, `FamilySize`, `Deck`, `AgeBin`, `FareBin` 以及交互特征 `AgeBin_Pclass`, `Title_Pclass`, `Sex_Pclass`），将模型替换为基于TensorFlow/Keras构建的神经网络分类器。
        *   **数据与预处理**: 与4.f节完全一致，使用完整 `train.csv` 数据集及相同的缺失值处理和特征工程策略。所有特征在输入神经网络前都经过了与之前实验一致的预处理（数值特征标准化，分类特征独热编码）。
        *   **模型**: 神经网络分类器，结构如下：
            *   输入层 (根据独热编码后的特征数量确定维度)
            *   Dense(128, activation='relu') + Dropout(0.3)
            *   Dense(64, activation='relu') + Dropout(0.3)
            *   Dense(32, activation='relu')
            *   输出层: Dense(1, activation='sigmoid')
        *   **编译与训练**:
            *   优化器: 'adam'
            *   损失函数: 'binary_crossentropy'
            *   评估指标: 'accuracy'
            *   训练轮数: 100 (配合EarlyStopping, patience=10, monitor='val_loss')
            *   批大小: 32
        *   **本地验证集准确率**: (请根据 `train_model.py` 脚本输出填写，例如: 0.79XXX)
        *   **Kaggle 公开排行榜得分**: **0.78468**
        *   **分析与讨论**:
            *   本次使用神经网络模型，在应用了与4.f节相同的特征工程后，Kaggle公开排行榜得分为0.78468。这一分数与4.f节中使用逻辑回归模型（手动设定参数 `C=0.1, penalty='l1'`）所达到的本地验证准确率（0.78468）完全相同。
            *   这表明，对于当前特征集，该神经网络结构和训练配置取得了与精心调参的逻辑回归模型相当的性能。
            *   与项目中其他模型的Kaggle得分对比：
                *   4.g节 XGBoost (GridSearchCV调优): 0.77990
                *   4.k节 SVM (固定参数): 0.77272
            *   该神经网络模型的表现在当前所有模型中达到了最佳（与4.f逻辑回归并列）。
            *   未来的改进方向可能包括：调整神经网络结构（层数、神经元数量、激活函数、Dropout率），尝试不同的优化器或学习率，或者进一步丰富特征工程。
            *   可以检查训练过程中的学习曲线（训练集与验证集的损失/准确率变化），以判断模型是否存在过拟合或欠拟合，并据此调整模型复杂度或正则化策略。 

    *   **4.m. 神经网络模型 (引入批归一化与结构调整)**
        *   **背景**: 此实验在4.l节的神经网络模型基础上进行优化，引入了批归一化 (Batch Normalization)，调整了网络结构，并更新了相关参数。
        *   **数据与预处理**: 与4.l节完全一致，使用4.f节的特征工程策略。
        *   **模型**: 神经网络分类器，结构如下：
            *   输入层 (根据独热编码后的特征数量确定维度)
            *   Dense(256, kernel_initializer='he_normal', use_bias=False) + BatchNormalization() + Activation('relu') + Dropout(0.5)
            *   Dense(128, kernel_initializer='he_normal', use_bias=False) + BatchNormalization() + Activation('relu') + Dropout(0.4)
            *   Dense(64, kernel_initializer='he_normal', use_bias=False) + BatchNormalization() + Activation('relu') + Dropout(0.3)
            *   输出层: Dense(1, activation='sigmoid')
        *   **编译与训练**:
            *   优化器: 'adam'
            *   损失函数: 'binary_crossentropy'
            *   评估指标: 'accuracy'
            *   训练轮数: 200 (配合EarlyStopping, patience=20, monitor='val_loss')
            *   批大小: 32
        *   **本地验证集准确率**: (请根据 `train_model.py` 脚本输出填写)
        *   **Kaggle 公开排行榜得分**: **0.78708**
        *   **分析与讨论**:
            *   本次优化的神经网络模型，在引入批归一化、调整网络结构（层大小变为256-128-64，使用he_normal初始化）、调整Dropout率（0.5, 0.4, 0.3）并增加EarlyStopping的patience(20)和训练轮数(200)后，Kaggle公开排行榜得分从0.78468提升至0.78708。
            *   这一提升表明批归一化和网络结构的调整对模型性能有积极影响，帮助模型取得了目前为止在Kaggle上的最高分。
            *   与项目中其他模型的Kaggle得分对比：
                *   4.l节 神经网络 (初始结构): 0.78468
                *   4.f节 逻辑回归 (手动调参): 本地验证0.78468 (Kaggle得分未直接记录，但4.l节NN与之持平)
                *   4.g节 XGBoost (GridSearchCV调优): 0.77990
                *   4.k节 SVM (固定参数): 0.77272
            *   此结果进一步巩固了神经网络在该任务上的领先地位。未来仍可探索学习率调整、更细致的正则化策略或尝试更先进的网络结构或优化器。 

    好的，我们来按照你提供的格式，总结本次集成模型（逻辑回归 + XGBoost，在基础特征集上手动软投票）的实验结果与分析。

由于你的上一个实验（4.m节）的Kaggle得分是0.78708，而我们这次的本地测试集准确率达到了0.8547，ROC AUC达到了0.8714，这通常预示着在Kaggle上也会有非常好的表现，甚至可能超越0.78708。但Kaggle的最终得分需要实际提交才能确认。

**我将基于我们本地测试集的评估结果来填写，并与你之前记录的其他模型进行对比。**

---

*   **4.n. 集成学习模型 (逻辑回归 + XGBoost 软投票)**
    *   **背景**: 此实验旨在通过集成两个在基础特征集上表现优异且参数已调优的模型——逻辑回归和XGBoost——来进一步提升预测性能。采用软投票机制平均它们的预测概率。
    *   **数据与预处理**: 使用在多次迭代中被证明对逻辑回归和XGBoost都表现稳健的**基础特征集**。预处理包括：中位数填充年龄（按Pclass和Sex分组后全局填充）、众数填充Embarked、独热编码分类特征（Embarked, Title）、创建FamilySize和IsAlone、对Fare进行0值处理和log1p转换，最后对数值特征进行标准化。
    *   **模型**: 手动软投票集成模型，包含以下两个基础模型：
        1.  **逻辑回归**:
            *   特征集: 基础特征集
            *   参数: `{'C': 1, 'penalty': 'l2', 'solver': 'liblinear', 'random_state': 42, 'max_iter': 2000}` (已知最佳)
        2.  **XGBoost 分类器**:
            *   特征集: 基础特征集
            *   参数: `{'objective': 'binary:logistic', 'eval_metric': 'auc', 'use_label_encoder': False, 'random_state': 42, 'colsample_bytree': 0.9, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.9}` (已知最佳)
        *   集成方式: 对两个模型输出的生还概率进行算术平均，然后基于0.5的阈值进行分类。
    *   **编译与训练**: 各基础模型独立训练，不涉及集成模型的额外编译或训练步骤（因为是手动概率平均）。
    *   **本地验证集准确率 (基于`train_test_split`的20%测试集)**: **0.8547**
    *   **本地验证集ROC AUC (基于`train_test_split`的20%测试集)**: **0.8714**
    *   **Kaggle 公开排行榜得分**: (需要实际提交 `final_titanic_submission.csv` 后填写)
    *   **分析与讨论**:
        *   本次实验通过集成两个在相同基础特征集上调优的逻辑回归和XGBoost模型，在本地验证集上取得了显著的性能提升。准确率达到0.8547，是目前所有迭代中最高的本地准确率。ROC AUC达到0.8714，非常接近单独逻辑回归创下的0.8740的记录，并优于单独的XGBoost。
        *   集成模型在“生还”这一少数类上的表现尤为突出，其Precision达到0.85，Recall为0.75，F1-score为0.80，均优于或持平于单个基础模型，表明集成有效地结合了两个模型的优势，在保持高召回率的同时显著提升了预测的精确性。
        *   与项目中其他模型在**本地验证集**上的表现对比（假设使用相同的`train_test_split`评估）：
            *   4.m节 神经网络 (优化结构，Kaggle得分0.78708): 本地验证准确率/AUC需回顾该实验记录。
            *   本次集成模型 (LR+XGBoost): 本地准确率 **0.8547**, 本地AUC **0.8714**
            *   逻辑回归 (基础特征集, 单独): 本地准确率 0.8380, 本地AUC 0.8740
            *   XGBoost (基础特征集, 单独): 本地准确率 0.8212, 本地AUC 0.8642
            *   XGBoost (V3特征集, 单独): 本地准确率 0.8045, 本地AUC 0.8593
            *   4.g节 XGBoost (GridSearchCV调优, Kaggle 0.77990): 本地验证准确率/AUC需回顾该实验记录。
        *   此结果表明，即使基础模型之一（逻辑回归）已经非常强大，通过与另一个不同类型的强模型（XGBoost）进行简单的软投票集成，仍有可能在整体准确率和关键类别的F1分数上获得进一步提升，同时保持高水平的AUC。这突出了模型多样性在集成学习中的重要性。
        *   未来的微调方向可以包括尝试带权重的软投票，或者调整最终的决策阈值以进一步平衡Precision和Recall。如果Kaggle得分与本地验证结果趋势一致，此集成模型有潜力成为最终的最佳方案。

---

**请注意：**

*   你需要将生成的 `final_titanic_submission.csv` 文件提交到Kaggle，才能获得真实的 **Kaggle 公开排行榜得分**，并填写到相应位置。
*   为了更准确地对比4.m节神经网络的本地验证性能，你需要回顾运行该脚本时的本地验证集输出。
*   如果你的Kaggle公开排行榜得分确实超过了0.78708，那将是一个非常棒的成果！

这个总结格式应该能很好地记录你这次成功的集成实验。